{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LogisticRegression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot_rT-q9oaw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For a sample array\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1V1IW9Goxeg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sigmoid function is hypothesis in logistic regression\n",
        "#     h(x) = g(thetaT.x) where g(z) = 1/1+e^-z and 0 <= h(x) <= 1 \n",
        "\n",
        "\n",
        "# Can use SGD to minimize loss(cost function)\n",
        "# cost = -log(h(x))     if y=1\n",
        "#      = -log(1- h(x))   if y=0\n",
        "# or cost = -ylog(h(x)) - (1-y)log(1- h(x))\n",
        "# ^ Implying if the actual class is 1 and the model predicts 0, we should penalize it and vice-versa\n",
        "\n",
        "# If the weighted sum of inputs > 0, the predicted class is 1 else 0 - binomial Logistic Regression\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1S6D3Fmzotfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(X, coeff):\n",
        "    c = np.dot(X, coeff.T)\n",
        "    cvec = np.multiply(X, coeff.T)\n",
        "#     print(\"cvec: {}, cvec.shape: {}, X.shape: {}\".format(cvec, cvec.shape, X.shape))\n",
        "    return 1.0/(1 + np.exp(-cvec)) \n",
        "\n",
        "def cost_function(X, y, coeff):\n",
        "#  as per the cost func defined in comments\n",
        "    hx = sigmoid(coeff, X)\n",
        "    c1 = y * np.log(hx) \n",
        "    c2 = (1 - y) * np.log(1 - hx) \n",
        "    final = -c1 - c2 \n",
        "    me = np.mean(final)\n",
        "    return me\n",
        "\n",
        "def gradient(X, y, coeff):\n",
        "    m = X.shape[0]\n",
        "    mult = np.multiply(sigmoid(X, coeff) - y, X.T)\n",
        "    return (1 / m) * mult\n",
        "    \n",
        "def gradient_descent(X, y, coeff, learning_rate = 0.01, min_cost_change= 0.001):\n",
        "    cost = cost_function(X, y, coeff) \n",
        "    cost_change = learning_rate\n",
        "    epoch = 1\n",
        "      \n",
        "    while(cost_change > min_cost_change): \n",
        "        prev_cost = cost \n",
        "        coeff = coeff - (learning_rate * gradient(X, y, coeff)) \n",
        "        cost = cost_function(X, y, coeff) \n",
        "        cost_change = prev_cost - cost \n",
        "        epoch += 1\n",
        "      \n",
        "    return coeff, epoch \n",
        "\n",
        "def predict_y(X, coeff): \n",
        "    pred_prob = sigmoid(coeff, X) \n",
        "    pred_value = np.where(pred_prob >= 0.5, 1, 0) \n",
        "    return pred_value\n",
        "\n",
        "if __name__ == \"__main__\": \n",
        "\n",
        "    X = np.array([0.50\t,0.75\t,1.00\t,1.25\t,1.50\t,1.75\t,2.00\t,2.25\t,2.50\t,2.75\t,3.00\t,3.25\t,3.50\t,3.75\t,4.00\t,4.25\t,4.50\t,4.75\t,5.00\t,5.50])\n",
        "    y = np.array([0\t,0\t,0\t,0\t,0\t,0\t,1\t,0\t,1\t,0\t,1\t,0\t,1\t,0\t,1\t,1\t,1\t,1\t,1\t,1])\n",
        "    # initial values \n",
        "    coeff = np.zeros(X.shape[1])\n",
        "\n",
        "    coeff, num_epochs = gradient_descent(X, y, coeff) \n",
        "  \n",
        "    print(\"Estimated regression coefficients:\", coeff) \n",
        "    print(\"No. of iterations:\", num_epochs) \n",
        "  \n",
        "    y_pred = predict_y(X, coeff) \n",
        "      \n",
        "    # number of correctly predicted labels \n",
        "    print(\"Total labels: \", y.size)\n",
        "    print(\"Correctly predicted labels:\", np.sum(y == y_pred)) "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}