{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN-full.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNfwGYvykmjx",
        "colab_type": "code",
        "outputId": "2de60f73-1767-4462-85fa-b4251bac4cf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Multiclass, multilayer neural network\n",
        "'''\n",
        "STEPS:\n",
        "1. Forward propagate\n",
        "2. Backward propagate\n",
        "3. Update params\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nSTEPS:\\n1. Forward propagate\\n2. Backward propagate\\n3. Update params\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFWX1fIKk2EF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split \n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChiisN-UTXX-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "np.set_printoptions(threshold=sys.maxsize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLQK696Xla6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature scaling\n",
        "def x_mean(a):\n",
        "  mean = np.mean(a, dtype=\"float128\")\n",
        "  func = np.vectorize(lambda t: t - mean)\n",
        "  return func(a)\n",
        "\n",
        "def std_var(a):\n",
        "  std = np.std(a, dtype=\"float128\")\n",
        "  if std == 0:#hack if all features are 1 or same; ideally in that case, remove the feature\n",
        "    std = 1\n",
        "  func = np.vectorize(lambda t: t / std)\n",
        "  return func(a)\n",
        "\n",
        "def feature_scaling(X):\n",
        "  X = np.apply_along_axis(x_mean, 0, X)\n",
        "  X = np.apply_along_axis(std_var, 0, X)\n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCYxDaODwwy6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(Z):\n",
        "  A = 1 / (1 + np.exp(-Z))\n",
        "  return A\n",
        "\n",
        "def sigmoid_gradient(A):\n",
        "#   A is sigmoid(Z) here\n",
        "  return np.multiply(A, (1 - A))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGSxFR-Iwxbe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_parameters(layerwise_neuron_dist):\n",
        "# Assign weights for hidden layers, o/p layer\n",
        "# For each neuron, 1 wt for each feature\n",
        "  parameters = {}\n",
        "  layers_num = len(layerwise_neuron_dist)\n",
        "  \n",
        "  for l in range(1, layers_num):\n",
        "    parameters[\"W\" + str(l)] = np.random.randn(layerwise_neuron_dist[l], layerwise_neuron_dist[l - 1])\n",
        "    parameters[\"b\" + str(l)] = np.zeros((layerwise_neuron_dist[l], 1))\n",
        "  return parameters\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCYyIa1qkEDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_propagate(A_prev, W, b):\n",
        "#   print(\"W.shape:\",W.shape)\n",
        "#   print(\"A_prev.\",A_prev.shape)\n",
        "#   print(\"b shape\", b.shape)\n",
        "#   b = b[:, :W.shape[1]] \n",
        "#   print(\"b:\",b.shape, \"w:\", W.shape)\n",
        "  Z = np.dot(W, A_prev) + b\n",
        "  A = sigmoid(Z)\n",
        "  return Z, A\n",
        "\n",
        "def layerwise_forward(X, parameters):\n",
        "#   layers_num = len(parameters) # which will be num of hidden layers + 1\n",
        "  layers_num= 3\n",
        "  A_prev = X\n",
        "  caches = []\n",
        "  \n",
        "  for l in range(1, layers_num+1):\n",
        "    W = parameters[\"W\" + str(l)]\n",
        "    b = parameters[\"b\" + str(l)]\n",
        "    linear_cache = (A_prev, W, b)\n",
        "\n",
        "    Z, A = forward_propagate(A_prev, W, b)\n",
        "    z_cache = Z\n",
        "    cache = (linear_cache, z_cache)\n",
        "    caches.insert(l, cache)\n",
        "    \n",
        "    A_prev = A\n",
        "    \n",
        "  return A, caches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nB46x-H9psY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cost_function(A, Y):\n",
        "  c1 = Y * np.log(A) \n",
        "  c2 = (1 - Y) * np.log(1 - A) \n",
        "  final = -c1 - c2 \n",
        "  me = np.mean(final)\n",
        "  return me"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XMhH-icqL7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def back_propagate(dA, cache):\n",
        "  A_prev, W, b = cache[0] #linear_cache\n",
        "  Z = cache[1] #z_cache\n",
        "  m = A_prev.shape[1]\n",
        "    \n",
        "  A = sigmoid(Z)\n",
        "  dZ = dA * sigmoid_gradient(A)\n",
        "\n",
        "  dW = np.dot(dZ, A_prev.T)\n",
        "  db = np.sum(dZ, axis=1, keepdims=True)\n",
        "  dA_prev = np.dot(W.T, dZ)\n",
        "\n",
        "  return dA_prev, dW, db\n",
        "\n",
        "def layerwise_backward(A, Y, caches):\n",
        "#   layers_num = len(caches) # num of layers = 3\n",
        "  Y = Y.reshape(A.shape)\n",
        "  layers_num = 3\n",
        "  deltas = {}\n",
        "  \n",
        "  err = A - Y\n",
        "  sig_gradient =  sigmoid_gradient(A)\n",
        "  dA = np.multiply(err, sig_gradient)\n",
        "  \n",
        "#   For last layer\n",
        "  cache = caches[layers_num-1]\n",
        "  A_prev, W, b = cache[0]\n",
        "  Z = cache[1]\n",
        "  \n",
        "  deltas[\"dA\" + str(layers_num-1)] = dA\n",
        "  deltas[\"db\" + str(layers_num)] = dA\n",
        "  deltas[\"dW\" + str(layers_num)] = np.dot(dA, A_prev.T)\n",
        "\n",
        "  for l in range(layers_num-1, 0, -1):\n",
        "    cache_1 = caches[l-1]\n",
        "    dA_1, dW, db = back_propagate(deltas[\"dA\" + str(l)], cache_1)\n",
        "    \n",
        "    deltas[\"dA\" + str(l - 1)] = dA_1 \n",
        "    deltas[\"dW\" + str(l)] = dW\n",
        "    deltas[\"db\" + str(l)] = db \n",
        "\n",
        "  return deltas\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiY4fjJ35gye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_params(params, deltas, learning_rate):\n",
        "#   layers_num = len(params)\n",
        "  layers_num = 3\n",
        "\n",
        "  for l in range(1, layers_num+1):\n",
        "    dW = deltas[\"dW\" + str(l)]\n",
        "    db = deltas[\"db\" + str(l)]\n",
        "    params[\"W\" + str(l)] = params[\"W\" + str(l)] - learning_rate * dW\n",
        "    params[\"b\" + str(l)] = params[\"b\" + str(l)] - learning_rate * db\n",
        "\n",
        "  return params"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOXkKFC2w70l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(X, Y, params, learning_rate = 0.01, max_epochs = 1000):\n",
        "#   Gradient descent\n",
        "  loss_list = []\n",
        "  \n",
        "  for epoch in range(max_epochs):\n",
        "    A, caches = layerwise_forward(X, params)\n",
        "    \n",
        "    loss = cost_function(A, Y)\n",
        "#     print(\"Epoch: \", epoch, \", loss: \", loss)\n",
        "    loss_list.append([loss, epoch])\n",
        "    \n",
        "    deltas = layerwise_backward(A, Y, caches)\n",
        "    \n",
        "    params = update_params(params, deltas, learning_rate)\n",
        "  \n",
        "  return params, loss_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EylteSeeTfB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_loss(loss_list):\n",
        "  # Plot loss over epoch\n",
        "  x_axis = np.array([i[1] for i in loss_list]) # epoch\n",
        "  y_axis = np.array([i[0] for i in loss_list]) # loss\n",
        "  plt.figure(figsize=(10,10))\n",
        "  plt.title(\"Loss over epochs\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.plot(x_axis, y_axis, label=\"training loss\")\n",
        "  plt.legend(loc=\"best\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER6WZQ91ktr2",
        "colab_type": "code",
        "outputId": "59fcbe4b-0798-4ee8-9650-a8f90b14320a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  digits = load_digits()\n",
        "  X = digits.data \n",
        "  y = digits.target\n",
        "  \n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)\n",
        "  print(\"Initial X_train.shape: \", X_train.shape)\n",
        "  print(\"Initial y_train.shape: \", y_train.shape)\n",
        "  \n",
        "  X_train_scaled = feature_scaling(X_train).T\n",
        "  X_test_scaled  = feature_scaling(X_test).T\n",
        "  \n",
        "  print(\"\\nAfter scaling:\")\n",
        "  print(\"X_train_scaled shape: \", X_train_scaled.shape)\n",
        "  print(\"X_test_scaled shape: \", X_test_scaled.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial X_train.shape:  (1257, 64)\n",
            "Initial y_train.shape:  (1257,)\n",
            "\n",
            "After scaling:\n",
            "X_train_scaled shape:  (64, 1257)\n",
            "X_test_scaled shape:  (64, 540)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihHH1O2pgFli",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare y training set\n",
        "y0_train = np.array(y_train == 0, dtype= int).reshape(1, -1)\n",
        "y1_train = np.array(y_train == 1, dtype= int).reshape(1, -1)\n",
        "y2_train = np.array(y_train == 2, dtype= int).reshape(1, -1)\n",
        "y3_train = np.array(y_train == 3, dtype= int).reshape(1, -1)\n",
        "y4_train = np.array(y_train == 4, dtype= int).reshape(1, -1)\n",
        "y5_train = np.array(y_train == 5, dtype= int).reshape(1, -1)\n",
        "y6_train = np.array(y_train == 6, dtype= int).reshape(1, -1)\n",
        "y7_train = np.array(y_train == 7, dtype= int).reshape(1, -1)\n",
        "y8_train = np.array(y_train == 8, dtype= int).reshape(1, -1)\n",
        "y9_train = np.array(y_train == 9, dtype= int).reshape(1, -1)\n",
        "\n",
        "y_train_all = [y0_train, y1_train, y2_train, y3_train, y4_train, y5_train, y6_train, y7_train, y8_train, y9_train]\n",
        "\n",
        "#   Initial values\n",
        "layerwise_neuron_dist = [X_train_scaled.shape[0], 10, 10, 1]\n",
        "param_list = []\n",
        "classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "\n",
        "# Train for each class\n",
        "for cl in classes:\n",
        "  params = initialize_parameters(layerwise_neuron_dist)\n",
        "  new_params, loss_list = train(X_train_scaled, y_train_all[cl], params)\n",
        "#   plot_loss(loss_list)\n",
        "  param_list.append(new_params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UA_Lg_UUg-9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict based on all classifiers\n",
        "def check(x):\n",
        "  if x >= 0.5:\n",
        "    return x\n",
        "  else:\n",
        "    return float(\"-inf\")\n",
        "  \n",
        "def sig_under_threshold(X, params):\n",
        "  A, ca = layerwise_forward(X, params)\n",
        "  \n",
        "  j = list(map(lambda x: check(x), A[0]))\n",
        "  return j\n",
        "  \n",
        "def predict(X, param_list): \n",
        "    prob_mat = sig_under_threshold(X, param_list[0])\n",
        "    prob_mat = np.vstack((prob_mat, sig_under_threshold(X, param_list[1])))\n",
        "    prob_mat = np.vstack((prob_mat, sig_under_threshold(X, param_list[2])))\n",
        "    prob_mat = np.vstack((prob_mat, sig_under_threshold(X, param_list[3])))\n",
        "    prob_mat = np.vstack((prob_mat, sig_under_threshold(X, param_list[4])))\n",
        "    prob_mat = np.vstack((prob_mat, sig_under_threshold(X, param_list[5])))\n",
        "    prob_mat = np.vstack((prob_mat, sig_under_threshold(X, param_list[6])))\n",
        "    prob_mat = np.vstack((prob_mat, sig_under_threshold(X, param_list[7])))\n",
        "    prob_mat = np.vstack((prob_mat, sig_under_threshold(X, param_list[8])))\n",
        "    prob_mat = np.vstack((prob_mat, sig_under_threshold(X, param_list[9])))\n",
        "    max_prob = np.argmax(prob_mat, 0)\n",
        "    return max_prob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XexT0zt5hgsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(y_true, y_estimate):\n",
        "  return np.sum(y_true == y_estimate, dtype = \"float\")/len(y_true)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efxjzV3zhkF9",
        "colab_type": "code",
        "outputId": "be7adc02-4020-48b7-b1f9-4cd6575c20b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#   Accuracy on set\n",
        "  X_true = X_train_scaled\n",
        "  y_true = y_test\n",
        "\n",
        "  y_estimate = predict(X_true, param_list)\n",
        "  print(y_true[:5])\n",
        "  print(y_estimate[:5])\n",
        "\n",
        "  acc = accuracy(y_true, y_estimate)\n",
        "  print(acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3 5 3 7 0]\n",
            "[3 5 3 7 0]\n",
            "0.9992044550517104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtmX6sgObrCL",
        "colab_type": "text"
      },
      "source": [
        "## **END**"
      ]
    }
  ]
}