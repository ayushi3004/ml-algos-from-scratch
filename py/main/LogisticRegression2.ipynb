{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LogisticRegression2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmzRUL7DS1Yk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For cancer dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbo3rzQ-knlO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(X, coeff):\n",
        "  dot = np.dot(X, coeff)\n",
        "  return 1.0/(1 + np.exp(-dot))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxM3HSfUaG-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature scaling\n",
        "def mean(a):\n",
        "  mean = float(np.mean(a))\n",
        "  func = np.vectorize(lambda t: t - mean)\n",
        "  return func(a)\n",
        "\n",
        "def std_var(a):\n",
        "  std = float(np.std(a))\n",
        "  func = np.vectorize(lambda t: t / std)\n",
        "  return func(a)\n",
        "\n",
        "def feature_scaling(X):\n",
        "  X = np.apply_along_axis(mean, 0, X)\n",
        "  X = np.apply_along_axis(std_var, 0, X)\n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiT3S-agrjJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalizeX(X):\n",
        "#   Change as per notation to get: w0x0 + w1x1 + w2x2 + ...\n",
        "# i.e. add an extra feature vector x0 for bias\n",
        "# Also do feature scaling\n",
        "  \n",
        "  shape = (X.shape[0], 1)\n",
        "  \n",
        "  newX = feature_scaling(X)\n",
        "  newX = np.hstack((np.ones(shape), newX))\n",
        "  \n",
        "  return newX\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZX4aKK7Ic9jy",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "#@title Default title text\n",
        "# To find theta: Gradient descent\n",
        "def gradient(X, y, theta):\n",
        "  m = y.shape[0]\n",
        "  sig = sigmoid(X, theta) \n",
        "  loss = sig - y\n",
        "  grad =  1/m * np.dot(X.T, loss)\n",
        "  return grad \n",
        "\n",
        "def cost_function(X, y, theta):\n",
        "  sig = sigmoid(X, theta) \n",
        "  c1 = y * np.log(sig) \n",
        "  c2 = (1 - y) * np.log(1 - sig) \n",
        "  final = -c1 - c2 \n",
        "  me = np.mean(final)\n",
        "  return me\n",
        "\n",
        "def gradient_descent(X, y, coeff, learning_rate = 0.01, min_cost_change = 0.001, max_epochs = 10000):\n",
        "  epoch = 1 \n",
        "  current_cost = cost_function(X, y, coeff) \n",
        "\n",
        "  while epoch < max_epochs:\n",
        "    prev_cost = current_cost\n",
        "    grad = gradient(X, y, coeff)\n",
        "    coeff = coeff - (learning_rate * grad) \n",
        "    current_cost = cost_function(X, y, coeff) \n",
        "    cost_change = prev_cost - current_cost\n",
        "#     print(\"cost_change:\", cost_change)\n",
        "    epoch += 1\n",
        "  \n",
        "  return coeff, epoch "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mmi5MGldtS1D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_y(X, coeff): \n",
        "    pred_prob = sigmoid(X, coeff)\n",
        "    pred_value = np.where(pred_prob >= 0.5, 1, 0) \n",
        "    return pred_value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHe_RldjS6SR",
        "colab_type": "code",
        "outputId": "93022808-4eb9-46dd-d2a7-51a54f1b51ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  dataset = datasets.load_breast_cancer()\n",
        "  X = dataset.data \n",
        "  y = dataset.target\n",
        "  \n",
        "#   dataset = datasets.load_iris()\n",
        "#   X = dataset.data\n",
        "#   y = dataset.target\n",
        "  \n",
        "  \n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) \n",
        "  \n",
        "  print(\"X_train.shape: \", X_train.shape)\n",
        "  print(\"y_train.shape: \", y_train.shape)\n",
        "  \n",
        "  X_train = normalizeX(X_train)\n",
        "  y_train = y_train.reshape((-1,1))\n",
        "  y_test = y_test.reshape((-1,1))\n",
        "  print(\"New X_train.shape after normalization: \", X_train.shape)\n",
        "  print(\"New y_train.shape after normalization: \", y_train.shape)\n",
        "  \n",
        "# #   Initial values\n",
        "#   coeff = np.zeros((X_train.shape[1], 1))\n",
        "#   coeff, epoch = gradient_descent(X_train, y_train, coeff)\n",
        "#   print(\"\\ncoeff.shape: \", coeff.shape)\n",
        "#   print(\"coefficients: \", coeff)\n",
        "#   print(\"epoch: \",epoch)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train.shape:  (398, 30)\n",
            "y_train.shape:  (398,)\n",
            "New X_train.shape after normalization:  (398, 31)\n",
            "New y_train.shape after normalization:  (398, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmcyVDFSUjbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = normalizeX(X_test)\n",
        "y_pred = predict_y(X_test, coeff).reshape((-1,1))\n",
        "# assert(y_pred.shape == (341,1))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_DBes6coZvp",
        "colab_type": "code",
        "outputId": "02cecdc2-ef7f-451b-b210-6ec3b97089a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_true = y_test\n",
        "def true_pos(y, y_pred):\n",
        "    return np.sum((y == 1) & (y_pred == 1))\n",
        "\n",
        "def true_neg(y, y_pred):\n",
        "    return np.sum((y == 0) & (y_pred == 0))\n",
        "  \n",
        "accuracy = (true_pos(y_true, y_pred) + true_neg(y_true, y_pred))/len(y_true)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9590643274853801\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3_uf7Mso5qM",
        "colab_type": "code",
        "outputId": "c124600a-b874-43b7-959a-85f999d9939f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X, y, test_size=0.4) \n",
        "model = LogisticRegression(solver = 'lbfgs', max_iter=10000)\n",
        "model.fit(X, y)\n",
        "y2_pred = model.predict(X2_train)\n",
        "accuracy2 = (true_pos(y2_train, y2_pred) + true_neg(y2_train, y2_pred))/len(y2_train)\n",
        "print(accuracy2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9648093841642229\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmnOXz-ub7vk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}